Matrix-matrix multiplication (\Gemm) is frequently used as a simple example with which to raise awareness of how to optimize modern processors.  A reason is that the operation is simple to describe, challenging to fully optimize, and of practical importance.  In this paper, we walk the reader through the techniques that underly the currently fastest implementations for CPU architectures.

\subsection{A minimal history}

Need to mention BLAS3~\cite{BLAS3} paper.

The advent of cache-based architectured, high-performance implementation of \Gemm\ necessitated careful attention to 
the amortization of the cost of data movement between memory layers and computation with that data~\cite{}.
To keep this manageable, it helps to realize that only a ``kernel'' that performs a  matrix-matrix multiplication with relatively small matrices needs to be highly optimized, since
computation with larger matrices can be blocked to then use such a kernel without an adverse impact on overall performance.  This 
insight was first explicitly advocated in
\begin{quote}
	Bo K\o{a}gstr\"{o}m , Per Ling , Charles Van Loan.\\
	 GEMM-based level 3 BLAS: high-performance model implementations and performance evaluation benchmark. \\
	  ACM Transactions on Mathematical Software (TOMS). \\
	  Volume 24 Issue 3, p.268-302, Sept. 1998.
\end{quote}

For more than a decade after that paper, the intricacies of 
high-performance optimization of \Gemm\ was considered to be 
sufficiently complex that it should be left to to the hardware vendors, yielding IBM's ESSL, Intel's MKL, Cray's ???, and AMD's ACML libraries, or auto-generated as advocated in papers on 
the Portable High Performance ANSI C (PHiPAC) guidelines for writing high-performance matrix-matrix multiplication in C~\cite{} and the Automatically Tuned Linear Algebra Software (ATLAS)~\cite{}.

Around 2000, Kazushige Goto revolutionized how \Gemm\ is implemented on current CPUs with his techniques
that were first published in the paper
\begin{quote}
	Kazushige Goto, Robert A. van de Geijn.\\
	\href{http://dl.acm.org/citation.cfm?id=1356052.1356053&coll=DL&dl=GUIDE&CFID=71223967&CFTOKEN=96440140}{Anatomy of high-performance matrix multiplication.}\\
	ACM Transactions on Mathematical Software (TOMS).\\
	Volume 34 Issue 3, May 2008, Article No. 12.
\end{quote}
At the end on this note we will discuss the major insights in this
paper.


\subsection{The BLIS-like Library Instantiation Software (BLIS)}

More recently, the BLAS-like Library Instantiation Software (BLIS) ``refactored'' the approach pioneered by Goto, exposing additional loops around a {\em micro-kernel}, as described in
\begin{quote}
	Field G. Van Zee, Robert A. van de Geijn. \\
	\href{http://dl.acm.org/citation.cfm?id=2786970.2764454&coll=DL&dl=GUIDE&CFID=702354034&CFTOKEN=48470379}{%
		BLIS: A Framework for Rapidly Instantiating BLAS Functionality.} \\
	ACM Transactions on Mathematical Software (TOMS).\\
	Volume 41 Issue 3, June 2015,
	Article No. 14.
\end{quote}
One goal of the BLIS paper was to further expose the layering of Goto's approach while simultaneously improving portability by reducing how much code must be written at a low level (e.g., in assembly code).

\subsection{You too can optimize like a pro}

The purpose of this note is to expose the basic techniques that 
underlie the best implementations of \Gemm\ so that you too can achieve high-performance for such operations.

