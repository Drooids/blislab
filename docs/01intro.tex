Matrix-matrix multiplication (\Gemm) is frequently used as a simple example with which to raise awareness of how to optimize modern processors.  A reason is that the operation is simple to describe, challenging to fully optimize, and of practical importance.  In this paper, we walk the reader through the techniques that underly the currently fastest implementations for CPU architectures.

\subsection{A minimal history}

Need to mention BLAS3~\cite{BLAS3} paper.


For more than a decade after that paper, the intricacies of 
high-performance optimization of \Gemm\ was considered to be 
sufficiently complex that it should be left to to the hardware vendors, yielding IBM's ESSL, Intel's MKL, Cray's ???, and AMD's ACML libraries, or auto-generated as advocated in papers on 
the Portable High Performance ANSI C (PHiPAC) guidelines for writing high-performance matrix-matrix multiplication in C~\cite{} and the Automatically Tuned Linear Algebra Software (ATLAS)~\cite{}.



\subsection{The BLIS-like Library Instantiation Software (BLIS)}

More recently, the BLAS-like Library Instantiation Software (BLIS) ``refactored'' the approach pioneered by Goto, exposing additional loops around a {\em micro-kernel}, as described in
\begin{quote}
	Field G. Van Zee, Robert A. van de Geijn. \\
	\href{http://dl.acm.org/citation.cfm?id=2786970.2764454&coll=DL&dl=GUIDE&CFID=702354034&CFTOKEN=48470379}{%
		BLIS: A Framework for Rapidly Instantiating BLAS Functionality.} \\
	ACM Transactions on Mathematical Software (TOMS).\\
	Volume 41 Issue 3, June 2015,
	Article No. 14.
\end{quote}
One goal of the BLIS paper was to further expose the layering of Goto's approach while simultaneously improving portability by reducing how much code must be written at a low level (e.g., in assembly code).

\subsection{You too can optimize like a pro}

The purpose of this note is to expose the basic techniques that 
underlie the best implementations of \Gemm\ so that you too can achieve high-performance for such operations.

